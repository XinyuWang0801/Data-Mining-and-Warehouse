{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2, 'c': 3}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'a':1,'b':2,'c':3}\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 1, 'a': 0, 'b': 3}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = {'1':1,'a':0,'b':3}\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(a) - set(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(b)-set(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1', 'c'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(set(a)-set(b)) | (set(b)-set(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6807b03ae70a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfool_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m## Please do not change the function defination...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m## Read the test data file, i.e., 'test_data.txt' from Present Working Directory...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google 云端硬盘/9318/COMP9318-Project/helper.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m## Please do not change these functions...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mcountcalls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0m__instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import helper\n",
    "import sklearn\n",
    "def fool_classifier(test_data): ## Please do not change the function defination...\n",
    "    ## Read the test data file, i.e., 'test_data.txt' from Present Working Directory...\n",
    "    \n",
    "    \n",
    "    ## You are supposed to use pre-defined class: 'strategy()' in the file `helper.py` for model training (if any),\n",
    "    #  and modifications limit checking\n",
    "    strategy_instance=helper.strategy() \n",
    "\n",
    "    x_train = strategy_instance.class0 + strategy_instance.class1\n",
    "\n",
    "    import numpy as np\n",
    "    y = np.zeros((540,1),dtype=np.int)\n",
    "\n",
    "    y[360:] = 1 \n",
    "    \n",
    "    y = y.ravel()\n",
    "\n",
    "#测试    \n",
    "    count_y1 = 0\n",
    "    for x in y:\n",
    "        if x == 1:\n",
    "            count_y1 += 1\n",
    "    #print('count_y1:',count_y1)\n",
    "#完毕\n",
    "    \n",
    "    def createVocabList(dataSet):\n",
    "        vocabSet=set([])\n",
    "        for document in dataSet:\n",
    "            vocabSet=vocabSet|set(document)\n",
    "        return list(vocabSet)\n",
    "    \n",
    "    \n",
    "    def setOfWords2Vec(vocabSet,inputSet):\n",
    "        returnVec=[0]*len(vocabSet)\n",
    "        for word in inputSet:\n",
    "            if word in vocabSet:\n",
    "                returnVec[vocabSet.index(word)]=1\n",
    "        return returnVec\n",
    "    \n",
    "    data = createVocabList(x_train)\n",
    "\n",
    "    trainAll=[]\n",
    "    for postinDoc in x_train:\n",
    "\n",
    "        trainAll.append(setOfWords2Vec(data,postinDoc))\n",
    "    \n",
    "    \n",
    "    trainAll = np.array(trainAll)\n",
    "\n",
    "    with open('test_data.txt','r') as test1:\n",
    "        test1=[line.strip().split(' ') for line in test1]\n",
    "    \n",
    "    testAll=[]\n",
    "    for postinDoc in test1:\n",
    "        testAll.append(setOfWords2Vec(data,postinDoc))\n",
    "    \n",
    "    parameters={} \n",
    "    parameters['C'] = 0.051\n",
    "    parameters['kernel'] = 'linear'\n",
    "    parameters['degree'] = 3\n",
    "    parameters['gamma'] = 'auto'\n",
    "    parameters['coef0'] = 1\n",
    "    clf = strategy_instance.train_svm(parameters,trainAll,y)\n",
    "#测试 test分类    \n",
    "    predict_test = clf.predict(testAll)\n",
    "    print('predict_test:\\n',predict_test)\n",
    "    #print('len(predict_test):\\n',len(predict_test))\n",
    "    count_1 = 0\n",
    "    for x in predict_test:\n",
    "        if x == 1:\n",
    "            count_1 += 1\n",
    "    print('count_1:',count_1)\n",
    "#   完毕\n",
    "#测试 class0 分类  \n",
    "    c0 = strategy_instance.class0\n",
    "    #print('class0:',class0)\n",
    "    \n",
    "    \n",
    "    c0All=[]\n",
    "    for postinDoc in c0:\n",
    "        #print('postinDoc:',postinDoc)\n",
    "        c0All.append(setOfWords2Vec(data,postinDoc))# 对 x_train的每个样例  返回该条样例中词出现在字典list中的位置  将位置的记录list加入trainALL\n",
    "    #print('c0All:',len(c0All))\n",
    "    predict_c0 = clf.predict(c0All)\n",
    "    print('predict_c0:\\n',predict_c0)\n",
    "    print('len(predict_c0):\\n',len(predict_c0))\n",
    "    count_c01 = 0\n",
    "    for x in predict_c0:\n",
    "        if x == 1:\n",
    "            count_c01 += 1\n",
    "    print('count_c01:',count_c01)\n",
    "#   完毕\n",
    "#测试 class1 分类  \n",
    "    c1 = strategy_instance.class1\n",
    "    #print('class1:',class1)\n",
    "    \n",
    "    \n",
    "    c1All=[]\n",
    "    for postinDoc in c1:\n",
    "        #print('postinDoc:',postinDoc)\n",
    "        c1All.append(setOfWords2Vec(data,postinDoc))# 对 x_train的每个样例  返回该条样例中词出现在字典list中的位置  将位置的记录list加入trainALL\n",
    "    #print('c0All:',len(c1All))\n",
    "    predict_c1 = clf.predict(c1All)\n",
    "    print('predict_c1:\\n',predict_c1)\n",
    "    print('len(predict_c1):\\n',len(predict_c1))\n",
    "    count_c11 = 0\n",
    "    for x in predict_c1:\n",
    "        if x == 1:\n",
    "            count_c11 += 1\n",
    "    print('count_c11:',count_c11)\n",
    "#   完毕\n",
    "    w = clf.coef_\n",
    "    index = np.where(w[0] < 0)[0]\n",
    "    \n",
    "    dic_w = {}\n",
    "    for i in index:\n",
    "        dic_w[i] = w[0][i]\n",
    "    dic_w = sorted(dic_w.items(), key=lambda d: d[1])[0:200]\n",
    "    \n",
    "    index = [dic_w[i][0] for i in range(len(dic_w))]\n",
    "    \n",
    "    add_word = []\n",
    "    for i in index:\n",
    "        add_word.append(data[i])\n",
    "    \n",
    "    n = 0\n",
    "    for i in range(len(test1)):\n",
    "        n = 0\n",
    "        for w in add_word:\n",
    "            if n == 20:\n",
    "                break\n",
    "            \n",
    "            if w not in test1[i]:\n",
    "                 test1[i].append(w)\n",
    "                \n",
    "            else:\n",
    "                continue\n",
    "            n = n + 1   \n",
    "    \n",
    "    file=open('./modified_data.txt','w')\n",
    "    for i in range(len(test1)):\n",
    "        file.write(\" \".join(test1[i]))\n",
    "        file.write(\"\\n\")\n",
    "    file.close()\n",
    "#测试modify    \n",
    "    with open('./modified_data.txt','r') as modified1:\n",
    "        modified1=[line.strip().split(' ') for line in modified1]\n",
    "    \n",
    "    modifiedAll=[]\n",
    "    for postinDoc in modified1:\n",
    "        modifiedAll.append(setOfWords2Vec(data,postinDoc))# 对test中每个样例处理 将样例中的词通过字典list位置映射起来\n",
    "    predict_modified = clf.predict(modifiedAll)\n",
    "    #print('predict_modified:\\n',predict_modified)\n",
    "    #print('len(predict_modified):\\n',len(predict_modified))\n",
    "    \n",
    "    count_m0 = 0\n",
    "    for x in predict_modified:\n",
    "        if x == 0:\n",
    "            count_m0 += 1\n",
    "    #print('count_m0:',count_m0)\n",
    "#完毕    \n",
    "    ## You can check that the modified text is within the modification limits.\n",
    "    modified_data='./modified_data.txt'\n",
    "    assert strategy_instance.check_data(test_data, modified_data)\n",
    "    return strategy_instance ## NOTE: You are required to return the instance of this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_test:\n",
      " [1 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 0\n",
      " 0 0 1 0 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1\n",
      " 0 1 1 0 0 1 0 0 0 1 1 0 0 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0\n",
      " 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1\n",
      " 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0]\n",
      "count_1: 89\n",
      "predict_c0:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "len(predict_c0):\n",
      " 360\n",
      "count_c01: 0\n",
      "predict_c1:\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "len(predict_c1):\n",
      " 180\n",
      "count_c11: 180\n"
     ]
    }
   ],
   "source": [
    "test_data='./test_data.txt'\n",
    "strategy_instance = fool_classifier(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['have', 'two', 'summer']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def createVocabList(dataSet):\n",
    "    vocabSet=set([])\n",
    "    for document in dataSet:\n",
    "        vocabSet=vocabSet|set(document)\n",
    "    return list(vocabSet)\n",
    "dataSet = [['have','two'],['summer','two']]\n",
    "d = createVocabList(dataSet)\n",
    "d\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def setOfWords2Vec(vocabSet,inputSet):#做一个len(字典list)大小的[0,0,0,0,……]  在inputSet中的每一个词，如果也在字典list中，对应位置标为1\n",
    "    returnVec=[0]*len(vocabSet)\n",
    "    for word in inputSet:\n",
    "        if word in vocabSet:\n",
    "            returnVec[vocabSet.index(word)]=1\n",
    "    return returnVec\n",
    "vocabSet = ['have', 'two', 'summer']\n",
    "inputSet = ['I','like','summer']\n",
    "s = setOfWords2Vec(vocabSet,inputSet)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
